\begin{abstract}
    This paper details a case study on formally verifying the robustness of neural network (NN) controllers designed for an autonomous driving system (ADS) simulated in Unity. We describe our methodology, encompassing iterative training of NN controllers of varying sizes using simulation data, formulation of \(L_\infty\)-based robustness properties (classification robustness, confidence lower bound, and local output stability), and integration with state-of-the-art verification tools. The central contribution is a benchmarking study comparing \(\alpha,\beta\)-CROWN and Marabou. We report results based on metrics including verification time, proof/falsification rates, and observed scalability limits across the different network architectures. This work provides practical insights and performance data from applying formal verification techniques within a closed-loop ADS simulation, contributing to the understanding of tool capabilities for safety assurance in this domain.
 

\keywords{Neural Network Verification, Autonomous Driving, Benchmarking}
\end{abstract}
